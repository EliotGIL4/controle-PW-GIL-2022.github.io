<!DOCTYPE html>
<html>

	<head>
		<meta charset="UTF-8">
		<link rel="stylesheet" href="pre_partie_grand_C.css">
		<title>Exercice 2 - Partie I. C.</title>
	</head>

	<body>
		<header>

			<h1>Sociologie du numérique</h1>

		</header>

			<section id="flex">

				<aside> 
					<div class="CV"><p><a href="../../../index.html">Retour au CV</a></p></div>
					<p><a href="../introduction/ex2.html">Introduction</a></p>
					<p>Partie I.  La création d'un nouveau cadre juridique et économique européen au service de la lutte contre l'hégémonie des Gafam</p>
					<p><a href="../pre_partie_grand_A/pre_partie_grand_A.html">Partie I. A. Un mouvement de déresponsabilisation des hébergeurs Internet hérité de la directive “E-Commerce” (2001)</a></p>
					<p><a href="../pre_partie_grand_B/pre_partie_grand_B.html">Partie I. B. Une démarche au goût d’inachevé : le Digital Market Act</a></p>
					<p><a href="pre_partie_grand_C.html">Partie I. C. La tentative incomplète d’une régulation sociale du marché numérique via le Digital Service Act</a></p>
					<p>Partie II. Les conséquences épistémiques de l’inefficacité des actions européennes contre l’influence des GAFAM</p>
					<p><a href="../deux_partie_grand_A/deux_partie_grand_A.html">Partie II. A. La conciliation du principe de neutralité du net et de la liberté d’expression</a></p>
					<p><a href="../deux_partie_grand_B/deux_partie_grand_B.html">Partie II. B. L'encadrement difficile des atteintes démocratiques par les GAFAM</a></p>
					<p><a href="../deux_partie_grand_C/deux_partie_grand_C.html">Partie II. C. L'implantation des sciences comportementales dans les algorithmes des réseaux sociaux</a></p>
					<p><a href="../conclusion/conclusion.html">Conclusion</a></p>
					<div class="CV"><p><a href="../../../index.html">Retour au CV</a></p></div>
				</aside>

				<article>
					<h2>Partie I. C. La tentative incomplète d’une régulation sociale du marché numérique via le Digital Service Act</h2>
					<img alt="image DSA" src="../image/DSA.jpeg" height="610" />
					<p>La proposition de Règlement dit « Digital Service Act » est née de la nécessité de combler les lacunes de l'article 14 de la directive sur le commerce électronique adoptée le 8 juin 2000 qui créait un régime d’irresponsabilité des hébergeurs vis-à-vis du contenu qu’ils hébergent. En effet, ils ne peuvent être tenus responsable que dans la mesure où ils n’auraient pas retiré un contenu illicite signalé par les utilisateurs et dont ils connaissaient l’existence.</p>
					<p>Cette première directive était justifiée par la nécessité de modérer les contenus tout en prenant en compte l’impossibilité pour les hébergeurs de surveiller tout ce qu’il se passe sur leurs plateformes. En ce sens, le considérant 42 de la directive précise le rôle « purement technique, automatique et passif » des hébergeurs « qui implique que le prestataire de services de la société de l'information n'ait pas la connaissance ni le contrôle des informations transmises ou stockées ». Cette définition s’oppose à celle de l’éditeur, qui a le pouvoir de contrôler les informations partagées.</p>
					<p>Cependant, concernant les réseaux sociaux, une ambiguïté persiste. En effet, les hébergeurs peuvent également être considérés comme « éditeurs » dans la mesure où ils trient, classent et sélectionnent les contenus. Juridiquement, ils sont quand même considérés comme étant seulement des hébergeurs, bénéficient donc du régime d’irresponsabilité. Une modération plus accrue leur donnerait le statut d’éditeur et ils perdraient ainsi le « privilège » du régime d’irresponsabilité. Il s’agit bien ici d’une faille de la directive sur le commerce électronique que le législateur européen tente aujourd’hui de combler.</p>
					<p><ul>En mai 2019, Emmanuel Macron rencontre Marc Zuckerberg afin d’établir un accord permettant à des fonctionnaires français de visiter les locaux de Facebook et observer comment la plateforme modère les contenus afin d’en tirer des leçons. Cet accord a permis de mettre en place ce qu’on appelle la « régulation supervision », similaire au système mis en place pour le marché des télécoms. Cet accord de principe a été transposé dans le DSA avec la supervision des risques systémiques garantie par son article 26. Trois grandes catégories de risques ont été identifiés : 
					<li>La diffusion de contenus illicites;</li>
					<li>Les effets négatifs sur la vie privée et familiale, la liberté d’expression et d’information, l’interdiction de la discrimination et les droits de l’enfant;</li>
					<li>Les manipulations intentionnelles des services, avec des effets négatifs ou prévisibles sur la protection de la santé, les mineurs, les discours civiques, les processus électoraux et la sécurité publique.</li></ul></p>
					<p>Ainsi, l'une des premières volontés du DSA est d'opérer un changement de paradigme par rapport à la directive e-commerce : l'Union européenne souhaite responsabiliser les hébergeurs par l'inclusion de leur participation active dans la lutte contre la haine en ligne.</p>
					<p>La modération des contenus telle que prévue par le DSA passerait également par un contrôle par la puissance publique, justifié par les impératifs de protection des droits fondamentaux des citoyens européens. Ce contrôle reste néanmoins relativement limité afin de préserver l’autonomie des réseaux sociaux. Il s’agit donc bien d’une logique de régulation qui permet une large marge de manœuvre aux plateformes dans l’établissement de leur politique de modération.</p>
					<p>L’une des faiblesses du DSA réside cependant dans le manque de précisions sur ce qui constitue un contenu illicite. En effet, concernant les discours de haine par exemple, le texte se contente de faire une renvoi aux dispositions applicables dans les Etats. C’est une opportunité manquée d’établir un cadre harmonisé et cela risque de compliquer davantage la modération des contenus pour les hébergeurs exerçant une activité eu Europe.</p>
					<p>Jean Cattan regrette également que le DSA « soit décorrélé des aspects économiques du fonctionnement des plateformes visés par le DMA ». Selon lui, les problèmes de contenus que le DSA tente de réguler sont étroitement liés au modèle économique développé par les hébergeurs et visé par le DMA. Dans ce cas, il serait intéressant d'utiliser la régulation économique afin d’atteindre les objectifs de régulation du contenu fixés par le DSA.</p>
					<p>Or, ces actions européennes ne sont pas sans conséquences, loin de là. Ce manque de cohérence et de précision des normes européennes laisse place à des répercussions sociales non-négligeables.</p>
				</article>

			</section>

		<footer>
			<div id="flex_bas">
				<p class="bas"><a href="#">  Pour remonter en haut, appuyez ici :)  </a></p>
			</div>
		</footer>

	</body>
	
</html>
